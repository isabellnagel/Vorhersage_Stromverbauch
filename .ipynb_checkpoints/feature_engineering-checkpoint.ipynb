{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59afc4b-b9be-4a03-b8cd-717f129efd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nbimporter\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69889f-7018-45cb-b6d4-307491eecf66",
   "metadata": {},
   "source": [
    "# 1. Korrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177eec0-5525-44b9-b8cc-29e7f8f8d4a8",
   "metadata": {},
   "source": [
    "## 1.1 Bestimmung korrelierender Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e92cf4-7100-4dae-8be6-4157bb98ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(endresult_df, categorical_columns, cut_off_limit):\n",
    "    \"\"\"\n",
    "    Erstellt eine Korrelationsmatrix und filtert die Spalten basierend auf einem Korrelationsschwellenwert.\n",
    "\n",
    "    Parameter:\n",
    "    endresult_df (DataFrame): Der ursprüngliche DataFrame, der analysiert wird.\n",
    "    categorical_columns (list): Eine Liste von kategorischen Spalten, die von der Korrelationsanalyse ausgeschlossen werden.\n",
    "    cut_off_limit (float): Der Schwellenwert für die absolute Korrelation. Spalten mit einer Korrelation unterhalb dieses Werts\n",
    "                           gegenüber der Zielspalte werden entfernt.\n",
    "\n",
    "    Rückgabewert:\n",
    "    DataFrame: Ein DataFrame, in dem die Spalten mit geringer Korrelation zur Zielspalte entfernt wurden.\n",
    "    \"\"\"\n",
    "\n",
    "    # Entfernen von kategorischen Spalten aus der Korrelationsanalyse\n",
    "    columns_to_keep = [col for col in endresult_df.columns if not any(excl in col for excl in categorical_columns)]\n",
    "\n",
    "    # Erstellen eines DataFrames nur mit relevanten numerischen Spalten\n",
    "    df_relevant = endresult_df[columns_to_keep]\n",
    "    \n",
    "    # Berechnen der Korrelationsmatrix\n",
    "    correlation_matrix = df_relevant.corr()\n",
    "    \n",
    "    # Größe der Figur festlegen\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Erstellen des Heatmaps für die Korrelationsmatrix\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    \n",
    "    # Titel hinzufügen\n",
    "    plt.title('Korrelationsmatrix Heatmap')\n",
    "    \n",
    "    # Plot anzeigen\n",
    "    plt.show()\n",
    "    \n",
    "    # Definieren der Zielspalte\n",
    "    target_column = \"Gesamt (Netzlast) [MWh] Originalauflösungen\"\n",
    "    \n",
    "    # Spalten ermitteln, die eine geringe Korrelation zur Zielspalte haben\n",
    "    columns_to_drop = correlation_matrix.index[abs(correlation_matrix[target_column]) < cut_off_limit].tolist()\n",
    "    \n",
    "    # Entfernen dieser Spalten aus dem relevanten DataFrame\n",
    "    df_filtered = df_relevant.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Wenn du die Korrelationsmatrix für den gefilterten DataFrame neu plotten möchtest\n",
    "    filtered_correlation_matrix = df_filtered.corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Erstellen des Heatmaps für die gefilterte Korrelationsmatrix\n",
    "    sns.heatmap(filtered_correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    \n",
    "    # Titel hinzufügen\n",
    "    plt.title('Gefilterte Korrelationsmatrix Heatmap')\n",
    "    \n",
    "    # Plot anzeigen\n",
    "    plt.show()\n",
    "\n",
    "    # Entfernen der nicht relevanten Spalten aus dem ursprünglichen DataFrame\n",
    "    df_end = endresult_df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Rückgabe des gefilterten DataFrames\n",
    "    return df_end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63469e-dae1-40fd-b6b2-0237d38ad427",
   "metadata": {},
   "source": [
    "## 1.2 Reduzierung der Dimensionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b88251-e830-4674-8400-b8cd90781d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducing_dimensionality(df, correlation_threshold, categorical_columns):\n",
    "    \"\"\"\n",
    "    Reduziert die Dimensionalität eines DataFrames, indem hochkorrelierte Spalten basierend auf einem festgelegten \n",
    "    Korrelationsschwellenwert entfernt werden.\n",
    "\n",
    "    Parameter:\n",
    "    df (DataFrame): Der Eingabe-DataFrame, der analysiert und reduziert werden soll.\n",
    "    correlation_threshold (float): Der Schwellenwert für die absolute Korrelation. Spaltenpaare mit einer höheren Korrelation\n",
    "                                   werden identifiziert und eine der beiden Spalten wird entfernt.\n",
    "    categorical_columns (list): Eine Liste von kategorischen Spalten, die von der Korrelationsanalyse ausgeschlossen werden.\n",
    "\n",
    "    Rückgabewert:\n",
    "    DataFrame: Ein DataFrame mit reduzierter Dimensionalität, bei dem hochkorrelierte Spalten entfernt wurden.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Entfernen von kategorischen Spalten aus der Korrelationsanalyse\n",
    "    columns_to_keep = [col for col in df.columns if not any(excl in col for excl in categorical_columns)]\n",
    "\n",
    "    # Filtern des DataFrames, um nur numerische Spalten zu behalten\n",
    "    df_filtered = df[columns_to_keep]\n",
    "    \n",
    "    # Berechnen der absoluten Korrelationsmatrix\n",
    "    correlation_matrix = df_filtered.corr().abs()\n",
    "    \n",
    "    # Erstellen einer Maske für das obere Dreieck der Korrelationsmatrix\n",
    "    upper_triangle_mask = np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    "    \n",
    "    # Finden der Spaltenpaare, die eine Korrelation über dem Schwellenwert haben\n",
    "    high_correlation_pairs = [(correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "                              for i, j in zip(*np.where(correlation_matrix > correlation_threshold))\n",
    "                              if upper_triangle_mask[i, j]]\n",
    "    \n",
    "    # Identifizieren der Spalten, die entfernt werden sollen\n",
    "    columns_to_drop = set([pair[1] for pair in high_correlation_pairs])\n",
    "    \n",
    "    # Entfernen der stark korrelierten Spalten aus dem DataFrame\n",
    "    df_reduced = df_filtered.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Optional: Korrelationsmatrix für den reduzierten DataFrame plotten\n",
    "    reduced_correlation_matrix = df_reduced.corr()\n",
    "    \n",
    "    # Größe der Figur festlegen\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Erstellen des Heatmaps für die reduzierte Korrelationsmatrix\n",
    "    sns.heatmap(reduced_correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    \n",
    "    # Titel hinzufügen\n",
    "    plt.title('Heatmap der gefilterten Features')\n",
    "    \n",
    "    # Plot anzeigen\n",
    "    plt.show()\n",
    "\n",
    "    # Entfernen der korrelierten Spalten aus dem ursprünglichen DataFrame\n",
    "    df_end = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Anzeigen des gefilterten DataFrames\n",
    "    print(df_end)\n",
    "    \n",
    "    # Rückgabe des reduzierten DataFrames\n",
    "    return df_end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167758bc-74b0-4d37-a3c3-a85d43e46b88",
   "metadata": {},
   "source": [
    "# 2. Encodierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913eeb2-7355-43b8-9edc-47368553367a",
   "metadata": {},
   "source": [
    "## 2.1 Ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f07b34e-4f6e-451d-a483-efddf67d2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_countries_by_viewership(football_dic_copy):\n",
    "    \"\"\"\n",
    "    Rangiert Länder basierend auf den Einschaltquoten in Deutschland und gibt ein Wörterbuch mit den Ländern und ihren Rangplätzen zurück.\n",
    "\n",
    "    Parameter:\n",
    "    football_dic_copy (dict): Ein Dictionary, das DataFrames für verschiedene Fußballspiele enthält. Jeder DataFrame sollte\n",
    "                               Spalten für die Länder (\"Land1\", \"Land2\") und die Einschaltquote (\"Einschaltquote (Deutschland)\") enthalten.\n",
    "\n",
    "    Rückgabewert:\n",
    "    dict: Ein Wörterbuch, das die Länder als Schlüssel und ihre Rangplätze basierend auf den Einschaltquoten als Werte enthält.\n",
    "    \"\"\"\n",
    "    \n",
    "    football_match = []\n",
    "    for key, match_set in football_dic_copy.items():\n",
    "        # Entfernen von führenden und nachfolgenden Leerzeichen in den Ländernamen\n",
    "        match_set[\"Land1\"] = match_set[\"Land1\"].str.strip()\n",
    "        match_set[\"Land2\"] = match_set[\"Land2\"].str.strip()\n",
    "        \n",
    "        try:\n",
    "            # Bereinigen und Konvertieren der Einschaltquote in eine numerische Form\n",
    "            match_set[\"Einschaltquote (Deutschland)\"] = match_set[\"Einschaltquote (Deutschland)\"].str.strip(\" Mio.\")\n",
    "            match_set[\"Einschaltquote (Deutschland)\"] = match_set[\"Einschaltquote (Deutschland)\"].str.replace(',', '.', regex=False)\n",
    "            match_set[\"Einschaltquote (Deutschland)\"] = pd.to_numeric(match_set[\"Einschaltquote (Deutschland)\"], errors='coerce')\n",
    "        \n",
    "            # Hinzufügen des bereinigten DataFrames zur Liste\n",
    "            football_match.append(match_set)\n",
    "        except:\n",
    "            # Fehler beim Verarbeiten der Einschaltquote ignorieren\n",
    "            pass\n",
    "    \n",
    "    # Kombinieren aller DataFrames in der Liste in einen einzigen DataFrame\n",
    "    result_df = pd.concat(football_match, ignore_index=True)\n",
    "    \n",
    "    # Auflösen der DataFrames, sodass jedes Land eine eigene Zeile erhält\n",
    "    df_melted = pd.melt(result_df, id_vars=[\"Einschaltquote (Deutschland)\"], value_vars=[\"Land1\", \"Land2\"],\n",
    "                        var_name='country_position', value_name='country')\n",
    "    \n",
    "    # Gruppieren nach Land und Summieren der Einschaltquoten\n",
    "    country_views = df_melted.groupby('country')[\"Einschaltquote (Deutschland)\"].sum().reset_index()\n",
    "    \n",
    "    # Rangieren der Länder nach den Gesamteinschaltquoten\n",
    "    view_df = country_views.sort_values(by=\"Einschaltquote (Deutschland)\", ascending=False).reset_index(drop=True)\n",
    "    view_df[\"Rank\"] = view_df.index + 1\n",
    "    \n",
    "    # Erstellen eines Wörterbuchs, das die Ländernamen den Rangplätzen zuordnet\n",
    "    country_to_rank = dict(zip(view_df['country'], view_df['Rank']))\n",
    "\n",
    "    return country_to_rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c44222-a22a-49d7-a3e9-739242005293",
   "metadata": {},
   "source": [
    "## 2.2 Cyclic Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95275c75-66f2-40a8-9a05-c4a778378e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_encoding(df_not_2024, categorical_columns, columns_to_normalize):\n",
    "    \"\"\"\n",
    "    Wendet zyklische Kodierung auf Zeitmerkmale an und normalisiert die angegebenen Spalten in einem DataFrame.\n",
    "\n",
    "    Parameter:\n",
    "    df_not_2024 (DataFrame): Der DataFrame, auf dem die zyklische Kodierung und Normalisierung angewendet werden.\n",
    "    categorical_columns (list): Eine Liste von kategorischen Spalten, die möglicherweise nicht normalisiert werden.\n",
    "    columns_to_normalize (list): Eine Liste von Spalten, die normalisiert werden sollen.\n",
    "\n",
    "    Rückgabewert:\n",
    "    DataFrame: Der DataFrame nach der zyklischen Kodierung und Normalisierung, wobei die Originalspalten der Zeitmerkmale entfernt wurden.\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Normalisieren der angegebenen Spalten\n",
    "    cyclic_normalized_df = df_not_2024.copy()\n",
    "    cyclic_normalized_df[columns_to_normalize] = scaler.fit_transform(cyclic_normalized_df[columns_to_normalize])\n",
    "    \n",
    "    # Zyklische Kodierung für Zeitmerkmale\n",
    "    cyclic_normalized_df['hour_sin'] = np.sin(2 * np.pi * cyclic_normalized_df['hour'] / 24)\n",
    "    cyclic_normalized_df['hour_cos'] = np.cos(2 * np.pi * cyclic_normalized_df['hour'] / 24)\n",
    "    \n",
    "    cyclic_normalized_df['day_sin'] = np.sin(2 * np.pi * cyclic_normalized_df['day'] / 31)\n",
    "    cyclic_normalized_df['day_cos'] = np.cos(2 * np.pi * cyclic_normalized_df['day'] / 31)\n",
    "    \n",
    "    cyclic_normalized_df['minute_sin'] = np.sin(2 * np.pi * cyclic_normalized_df['minute'] / 60)\n",
    "    cyclic_normalized_df['minute_cos'] = np.cos(2 * np.pi * cyclic_normalized_df['minute'] / 60)\n",
    "    \n",
    "    cyclic_normalized_df['day_of_week_sin'] = np.sin(2 * np.pi * cyclic_normalized_df['day_of_week'] / 7)\n",
    "    cyclic_normalized_df['day_of_week_cos'] = np.cos(2 * np.pi * cyclic_normalized_df['day_of_week'] / 7)\n",
    "\n",
    "    # Entfernen der ursprünglichen Zeitmerkmal-Spalten, falls gewünscht\n",
    "    cyclic_normalized_df.drop(['hour', 'day', 'minute', 'day_of_week'], axis=1, inplace=True)\n",
    "    \n",
    "    return cyclic_normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec74b00-3de2-40c0-9e17-0536bac58ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
