{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59afc4b-b9be-4a03-b8cd-717f129efd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nbimporter\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69889f-7018-45cb-b6d4-307491eecf66",
   "metadata": {},
   "source": [
    "# 1. Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177eec0-5525-44b9-b8cc-29e7f8f8d4a8",
   "metadata": {},
   "source": [
    "## 1.1 Detecting features by high correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e92cf4-7100-4dae-8be6-4157bb98ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlation_matrix(endresult_df, categorical_columns, cut_off_limit):\n",
    "    columns_to_keep = [col for col in endresult_df.columns if not any(excl in col for excl in categorical_columns)]\n",
    "\n",
    "    df_relevant = endresult_df[columns_to_keep]  \n",
    "    correlation_matrix = df_relevant.corr()\n",
    "    \n",
    "    # Set the size of the figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create the heat map\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    \n",
    "    # Add a title\n",
    "    plt.title('Correlation Matrix Heatmap')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    target_column = \"Gesamt (Netzlast) [MWh] Originalaufl√∂sungen\"\n",
    "    \n",
    "    columns_to_drop = correlation_matrix.index[abs(correlation_matrix[target_column]) < cut_off_limit].tolist()\n",
    "    \n",
    "    # Drop those columns from df_relevant\n",
    "    df_filtered = df_relevant.drop(columns=columns_to_drop)\n",
    "    #print(df_filtered)\n",
    "    # If you want to replot the correlation matrix for the filtered dataframe\n",
    "    filtered_correlation_matrix = df_filtered.corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create the heatmap\n",
    "    sns.heatmap(filtered_correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    \n",
    "    # Add a title\n",
    "    plt.title('Filtered Correlation Matrix Heatmap')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    df_end = endresult_df.drop(columns=columns_to_drop)\n",
    "    return df_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63469e-dae1-40fd-b6b2-0237d38ad427",
   "metadata": {},
   "source": [
    "## 1.2 Reducing dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b88251-e830-4674-8400-b8cd90781d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correlation threshold\n",
    "#correlation_threshold = 0.8  # Adjust this threshold as needed\n",
    "def reducing_dimensionality(df, correlation_threshhold,categorical_columns):\n",
    "# Calculate the correlation matrix\n",
    "    columns_to_keep = [col for col in df.columns if not any(excl in col for excl in categorical_columns)]\n",
    "\n",
    "    df_filtered = df[columns_to_keep]\n",
    "    correlation_matrix = df_filtered.corr().abs()\n",
    "    \n",
    "    # Create a boolean mask to identify the upper triangle of the correlation matrix\n",
    "    upper_triangle_mask = np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    "    \n",
    "    # Find the pairs of columns with correlation above the threshold\n",
    "    high_correlation_pairs = [(correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "                              for i, j in zip(*np.where(correlation_matrix > correlation_threshold))\n",
    "                              if upper_triangle_mask[i, j]]\n",
    "    \n",
    "    # Identify the columns to drop\n",
    "    columns_to_drop = set([pair[1] for pair in high_correlation_pairs])\n",
    "    \n",
    "    # Drop the highly correlated columns\n",
    "    df_reduced = df_filtered.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # If you want to replot the correlation matrix for the reduced dataframe\n",
    "    reduced_correlation_matrix = df_reduced.corr()\n",
    "    \n",
    "    # Set the size of the figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create the heatmap\n",
    "    sns.heatmap(reduced_correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    \n",
    "    # Add a title\n",
    "    plt.title('Reduced Correlation Matrix Heatmap')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    df_end = df.drop(columns=columns_to_drop)\n",
    "    print(df_end)\n",
    "    return df_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167758bc-74b0-4d37-a3c3-a85d43e46b88",
   "metadata": {},
   "source": [
    "# 2. Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913eeb2-7355-43b8-9edc-47368553367a",
   "metadata": {},
   "source": [
    "## 2.1 Ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f07b34e-4f6e-451d-a483-efddf67d2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_countries_by_viewership(football_dic_copy):\n",
    "    football_match = []\n",
    "    for key, match_set in football_dic_copy.items():\n",
    "        \n",
    "        match_set[\"Land1\"] = match_set[\"Land1\"].str.strip()\n",
    "        match_set[\"Land2\"] = match_set[\"Land2\"].str.strip()\n",
    "        try:\n",
    "            match_set[\"Einschaltquote (Deutschland)\"] = match_set[\"Einschaltquote (Deutschland)\"].str.strip(\" Mio.\")\n",
    "            match_set[\"Einschaltquote (Deutschland)\"] =  match_set[\"Einschaltquote (Deutschland)\"].str.replace(',', '.', regex=False)\n",
    "        \n",
    "            match_set[\"Einschaltquote (Deutschland)\"] = pd.to_numeric(match_set[\"Einschaltquote (Deutschland)\"], errors='coerce')\n",
    "        \n",
    "            football_match.append(match_set)\n",
    "        except:\n",
    "            pass\n",
    "        # Flatten the DataFrame by melting it, so each country gets its own row\n",
    "    \n",
    "    #print(football_match)\n",
    "    result_df = pd.concat(football_match, ignore_index = True)\n",
    "    \n",
    "    df_melted = pd.melt(result_df, id_vars=[\"Einschaltquote (Deutschland)\"], value_vars=[\"Land1\", \"Land2\"],\n",
    "                    var_name='country_position', value_name='country')\n",
    "    \n",
    "    # Group by country and sum the views\n",
    "    country_views = df_melted.groupby('country')[\"Einschaltquote (Deutschland)\"].sum().reset_index()\n",
    "    \n",
    "    # Rank the countries by total views\n",
    "    view_df = country_views.sort_values(by=\"Einschaltquote (Deutschland)\", ascending=False).reset_index(drop = True)\n",
    "    view_df[\"Rank\"] = view_df.index + 1\n",
    "    #print(view_df)\n",
    "    \n",
    "    # Create a dictionary mapping country names to their ranks\n",
    "    country_to_rank = dict(zip(view_df['country'], view_df['Rank']))\n",
    "\n",
    "    return country_to_rank\n",
    "    \n",
    "    #print(match_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bb666-0855-4960-a470-5115e11c7e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
