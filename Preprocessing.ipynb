{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2056d3bd-fefe-4706-8f9a-5d9832f7ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nbimporter\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17e6ce-a35d-4086-a639-3adeb298ae3c",
   "metadata": {},
   "source": [
    "# 1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344648bf-b5b7-497c-98d7-1ea8f763c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importing_climate_data(temp_path, temp_file, column_name, date_format):  \n",
    "    #temp_path =r\"C:\\Users\\Isabell\\EMSI\\emsi_ml\\Wetter\\Berlin\\df\"\n",
    "    #temp_file = glob.glob(os.path.join(temp_path, \"produkt*\"))\n",
    "    temp_file = glob.glob(os.path.join(temp_path, temp_file))\n",
    "    df_dic = {}\n",
    "    years_of_interest = [2016, 2018, 2021, 2024]\n",
    "    #years_of_interest = [2024]\n",
    "    #print(years_of_interest)\n",
    "    for file in temp_file:\n",
    "        df = pd.read_csv(file, delimiter = \";\")\n",
    "        #print(df)\n",
    "        df[\"DateTime\"] = pd.to_datetime(df[column_name], format= date_format)\n",
    "        #print(df)\n",
    "        for year in years_of_interest:\n",
    "            \n",
    "            #print(df)\n",
    "            data = df[df[\"DateTime\"].dt.year == year]\n",
    "            #data.set_index(\"DateTime\", inplace = True)\n",
    "            \n",
    "            #print(data)\n",
    "            if not data.empty:\n",
    "                exclude_col = \"DateTime\"\n",
    "                data.columns = [station + \"_\" + col if col != exclude_col else col for col in data.columns]\n",
    "                df_dic[year] =  data\n",
    "    \n",
    "    return df_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d19296d-8320-4c15-9d73-cf57e4b48352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importing_football_data(temp_path, temp_file, column_name, *date_format):  \n",
    "\n",
    "    temp_file = glob.glob(os.path.join(temp_path, temp_file))\n",
    "    df_dic = {}\n",
    "    years_of_interest = [2016, 2018, 2021, 2024]\n",
    "    #years_of_interest = [2024]\n",
    "    \n",
    "    for file in temp_file:\n",
    "        df = pd.read_csv(file, delimiter = \";\")\n",
    "        \n",
    "        df[\"DateTime\"] = df[\"Datum\"] + \" \" + df[\"Uhrzeit (MESZ)\"]\n",
    "\n",
    "        if \"EM\" in file:\n",
    "            df[\"Liga\"] = \"EM\"\n",
    "        elif \"WM\" in file:\n",
    "            df[\"Liga\"] = \"WM\"\n",
    "        \n",
    "        try:\n",
    "            df[\"DateTime\"] = pd.to_datetime(df[column_name], format= date_format[0])\n",
    "        except:\n",
    "            df[\"DateTime\"] = pd.to_datetime(df[column_name], format= date_format[1])\n",
    "\n",
    "        #print(df)\n",
    "        for year in years_of_interest:\n",
    "            \n",
    "            #print(df)\n",
    "            data = df[df[\"DateTime\"].dt.year == year]\n",
    "\n",
    "            if not data.empty:\n",
    "                df_dic[year] =  data\n",
    "    \n",
    "    return df_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726d2052-bf65-4ed6-8ed5-c8ffdcf5ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def importing_electricity_data(temp_path, file_name, date_column, date_format):\n",
    "    csv_files = glob.glob(os.path.join(temp_path, file_name))\n",
    "    \n",
    "    years_of_interest = [2016, 2018, 2021, 2024]\n",
    "    #years_of_interest = [2024]\n",
    "    stromverbrauch_list = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        #folder_path = r\"C:\\Users\\Isabell\\EMSI\\emsi_ml\\Stromverbrauch\\Viertel\\Realisierter_Stromverbrauch_201506070000_201506100000_Viertelstunde.csv\"\n",
    "        df = pd.read_csv(file, delimiter = \";\")\n",
    "        df[\"DateTime\"] = pd.to_datetime(df[date_column], format = date_format)\n",
    "    \n",
    "        for year in years_of_interest:\n",
    "        \n",
    "            #print(df)\n",
    "            data = df[df[\"DateTime\"].dt.year == year]\n",
    "            data.set_index(\"DateTime\", inplace = True)\n",
    "            \n",
    "            #print(data)\n",
    "            if not data.empty:\n",
    "                \n",
    "                df['Gesamt (Netzlast) [MWh] Originalauflösungen'] = df['Gesamt (Netzlast) [MWh] Originalauflösungen'].str.replace('.', '', regex=False)\n",
    "                df['Gesamt (Netzlast) [MWh] Originalauflösungen'] = df['Gesamt (Netzlast) [MWh] Originalauflösungen'].str.replace(',', '.', regex=False)\n",
    "                #print(df['Gesamt (Netzlast) [MWh] Originalauflösungen'])\n",
    "                # Step 2: Convert to numeric\n",
    "                df['Gesamt (Netzlast) [MWh] Originalauflösungen'] = df['Gesamt (Netzlast) [MWh] Originalauflösungen'].astype(float)\n",
    "                stromverbrauch_list.append(df)\n",
    "    \n",
    "    \n",
    "    df_tuples = [(df[\"DateTime\"].iloc[0], df) for df in stromverbrauch_list ]\n",
    "    \n",
    "    # Sort the list of tuples by the earliest date\n",
    "    df_tuples_sorted = sorted(df_tuples, key=lambda x: x[0])\n",
    "    \n",
    "    elec_dic = {}\n",
    "    \n",
    "    # Iterate over the list of tuples\n",
    "    for dt, df in df_tuples_sorted:  # Correctly unpack: dt is the date, df is the DataFrame\n",
    "        year = dt.year  # Extract the year from the date\n",
    "        \n",
    "        if year not in elec_dic:\n",
    "            elec_dic[year] = df\n",
    "        else:\n",
    "            # Merge the DataFrame with the existing one for the same year\n",
    "            elec_dic[year] = pd.concat([elec_dic[year], df], ignore_index=True)\n",
    "    \n",
    "    # Extract the sorted DataFrames into a list\n",
    "    sorted_df_list = [df_tuple[1] for df_tuple in df_tuples_sorted]\n",
    "\n",
    "    return elec_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d17fa-f97e-4d10-95ee-7f555439d055",
   "metadata": {},
   "source": [
    "# 2. Manipulating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c074fe25-affb-4a51-a49f-0d0e4f4a3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling_data(required_dic, resample_step):\n",
    "    resampled_dic = {}\n",
    "    for key, climate_df in required_dic.items():\n",
    "        try:\n",
    "            climate_df.set_index(\"DateTime\", inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        numeric_cols = climate_df.select_dtypes(include='number').columns\n",
    "        df_resampled_numeric = climate_df[numeric_cols].resample(resample_step).mean()\n",
    "    \n",
    "        # Resample non-numeric columns\n",
    "        non_numeric_cols = climate_df.select_dtypes(exclude='number').columns\n",
    "        df_resampled_non_numeric = climate_df[non_numeric_cols].resample(resample_step).agg(lambda x: x.mode()[0] if not x.mode().empty else x.iloc[0])\n",
    "    \n",
    "        # Combine the resampled numeric and non-numeric dataframes\n",
    "        df_resampled = pd.concat([df_resampled_numeric, df_resampled_non_numeric], axis=1)\n",
    "    \n",
    "        resampled_dic[key] = df_resampled\n",
    "\n",
    "    return resampled_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e80a009-994b-44aa-8965-4e4a809db4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col_match(match_set):\n",
    "    #print(\"Hello\")\n",
    "    match_set[\"Land1\"] = match_set[\"Land1\"].str.strip()\n",
    "    match_set[\"Land2\"] = match_set[\"Land2\"].str.strip()\n",
    "    match_set = match_set.loc[:, [\"Land1\", \"Land2\", \"Runde\", \"Liga\", \"DateTime\"]]\n",
    "    #print(spielplan)\n",
    "    grouped = match_set.groupby(\"DateTime\")\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for name, group in grouped:\n",
    "        if len(group) == 1:\n",
    "            results = pd.concat([results, group])\n",
    "            #print(\"yes\")\n",
    "        else:\n",
    "            land1_value = group.iloc[0]['Land1']\n",
    "            land2_value = group.iloc[0]['Land2']\n",
    "\n",
    "            new_row = {\n",
    "                \"DateTime\" : name,\n",
    "                'Land1': land1_value,\n",
    "                'Land2': land2_value,\n",
    "                \"Runde\" : group.iloc[1][\"Runde\"],\n",
    "                \"Liga\": group.iloc[1][\"Liga\"],\n",
    "                'Land3': group.iloc[1]['Land1'],\n",
    "                'Land4': group.iloc[1]['Land2'],\n",
    "                \n",
    "            }\n",
    "\n",
    "            new_df = pd.DataFrame([new_row])\n",
    "            #print(new_df)        \n",
    "            results = pd.concat([results, new_df], ignore_index = True)\n",
    "            print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e139a-9be5-4cbb-8236-886290a3b47b",
   "metadata": {},
   "source": [
    "# 3. Merging Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9aa841cf-5188-4108-94b4-b50a47f01929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_data(electricity_data, football_data, climate_data, unwantend_col_string):\n",
    "    dfs_year = []\n",
    "    dfs_year.append(electricity_data)\n",
    "    dfs_year.append(football_data)\n",
    "    for data in climate_data:\n",
    "        dfs_year.append(data)\n",
    "    \n",
    "    start_elec = electricity_data[\"DateTime\"].iloc[0]\n",
    "    end_elec = electricity_data[\"DateTime\"].iloc[-1]\n",
    "\n",
    "        #print(station[key][\"DateTime\"])\n",
    "    #print(dfs_year)\n",
    "    merged_df = reduce(lambda left, right: pd.merge(left, right, on='DateTime', how='outer'), dfs_year)\n",
    "\n",
    "    #print(merged_df[\"Land1\"].unique())\n",
    "\n",
    "    #print(elec)\n",
    "    spielplan_name_list = football_data.columns.tolist()\n",
    "\n",
    "    #print(football_dic[key])\n",
    "    for index, row in football_data.iterrows():\n",
    "        start_time = row[\"DateTime\"]\n",
    "        \n",
    "        until_time = row[\"DateTime\"] + timedelta(minutes=105)\n",
    "        #print(until_time)\n",
    "        fill_condition = (merged_df['DateTime']>= start_time) & (merged_df['DateTime'] <= until_time)\n",
    "        \n",
    "        merged_df.loc[fill_condition,spielplan_name_list] = merged_df.loc[fill_condition, spielplan_name_list].fillna(method='ffill')\n",
    "\n",
    "\n",
    "    for string in unwantend_col_string:\n",
    "        merged_df = merged_df.drop(columns = merged_df.filter(like=string).columns)\n",
    "        \n",
    "    merged_df = merged_df[(merged_df[\"DateTime\"] >= start_elec) & (merged_df[\"DateTime\"] <= end_elec)]\n",
    "\n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fbc2e-b794-4333-888d-f1aa63c05e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
